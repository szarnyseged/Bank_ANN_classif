{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e14c8361-d4a7-469c-96b9-b38dc9533424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset: bank costumers are leaving the bank. your job is to build a model to figure out,\n",
    "# why, and who will potentially leave the bank (exited column). (the bank can target them with special offer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a81006b-2fcc-4089-a417-289e5b078d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bfa36c-2ae7-42e4-b618-d03effbce65b",
   "metadata": {},
   "source": [
    "# 1. preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f37ec3-a1a2-4773-bddb-17612af43aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Churn_Modelling.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eda965e8-418a-40c2-8210-13902d2c7ea5",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
      "0          619    France  Female   42       2       0.00              1   \n",
      "1          608     Spain  Female   41       1   83807.86              1   \n",
      "2          502    France  Female   42       8  159660.80              3   \n",
      "3          699    France  Female   39       1       0.00              2   \n",
      "4          850     Spain  Female   43       2  125510.82              1   \n",
      "\n",
      "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
      "0          1               1        101348.88  \n",
      "1          0               1        112542.58  \n",
      "2          1               0        113931.57  \n",
      "3          0               0         93826.63  \n",
      "4          1               1         79084.10  \n",
      "\n",
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# remove unnecessary columns\n",
    "# no missing data\n",
    "X_independent = df.iloc[:, 3:-1]\n",
    "y_dependent = df.iloc[:, -1]\n",
    "print(X_independent.head())\n",
    "print(\"\")\n",
    "print(y_dependent.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61f32a81-7f62-47e1-9145-b4e98a470670",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first line:  [1.0 0.0 1.0 0.0 0.0 619 42 2 0.0 1 1 1 101348.88]\n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "[[1.0 0.0 1.0 ... 1 1 101348.88]\n",
      " [1.0 0.0 0.0 ... 0 1 112542.58]\n",
      " [1.0 0.0 1.0 ... 1 0 113931.57]\n",
      " ...\n",
      " [1.0 0.0 1.0 ... 0 1 42085.58]\n",
      " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
      " [1.0 0.0 1.0 ... 1 0 38190.78]]\n",
      "\n",
      "type of y_dependent:  <class 'numpy.ndarray'>\n",
      "y_dependent:  [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "y_dependent = np.array(y_dependent).reshape(-1, 1)\n",
    "ct_geography = ColumnTransformer(transformers=[(\"encoder\", OneHotEncoder(), [1])], remainder=\"passthrough\")\n",
    "X_independent = np.array(ct_geography.fit_transform(X_independent))\n",
    "\n",
    "# this can be used to see, the transformed dataset as a dataframe with the names.\n",
    "# why? -> transforming more columns -> chaotic to see what is what.\n",
    "#X_new_df = pd.DataFrame(X_independent, columns=ct_geography.get_feature_names_out())\n",
    "#print(\"new_df with labels: \", X_new_df)\n",
    "\n",
    "ct_gender = ColumnTransformer(transformers=[(\"transformer\", OneHotEncoder(), [4])], remainder=\"passthrough\")\n",
    "X_independent = np.array(ct_gender.fit_transform(X_independent))\n",
    "print(\"first line: \", X_independent[0])\n",
    "print(\"\")\n",
    "print(type(X_independent))\n",
    "print(X_independent)\n",
    "print(\"\")\n",
    "print(\"type of y_dependent: \", type(y_dependent))\n",
    "print(\"y_dependent: \", y_dependent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abe8f0b4-7c68-48b6-ba25-5c3fc4f311e2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (7000, 13)\n",
      "X_train: \n",
      " [[1.0 0.0 0.0 ... 0 1 140676.98]\n",
      " [0.0 1.0 1.0 ... 1 1 141476.56]\n",
      " [0.0 1.0 0.0 ... 1 0 22447.85]\n",
      " ...\n",
      " [0.0 1.0 0.0 ... 1 1 138051.19]\n",
      " [0.0 1.0 1.0 ... 1 1 141822.8]\n",
      " [1.0 0.0 0.0 ... 1 1 96658.26]]\n",
      "\n",
      "y_test shape:  (3000, 1)\n",
      "y_test: \n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_independent, y_dependent, test_size=0.3, random_state=101)\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_train: \\n\", X_train)\n",
    "print(\"\")\n",
    "print(\"y_test shape: \", y_test.shape)\n",
    "print(\"y_test: \\n\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06ef02fd-6893-44c9-a35e-1befb99d33d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first line:  [ 1.09759938 -1.09759938 -1.01496917 -0.57339125  1.75478035 -1.45057405\n",
      " -0.93156572  1.37687702 -1.23805017  0.80996205 -1.56090554  0.9793559\n",
      "  0.70308176]\n",
      "X_train_std_scaled:  [[ 1.09759938 -1.09759938 -1.01496917 ... -1.56090554  0.9793559\n",
      "   0.70308176]\n",
      " [-0.91107923  0.91107923  0.9852516  ...  0.64065376  0.9793559\n",
      "   0.71692473]\n",
      " [-0.91107923  0.91107923 -1.01496917 ...  0.64065376 -1.02107926\n",
      "  -1.34379489]\n",
      " ...\n",
      " [-0.91107923  0.91107923 -1.01496917 ...  0.64065376  0.9793559\n",
      "   0.657622  ]\n",
      " [-0.91107923  0.91107923  0.9852516  ...  0.64065376  0.9793559\n",
      "   0.72291911]\n",
      " [ 1.09759938 -1.09759938 -1.01496917 ...  0.64065376  0.9793559\n",
      "  -0.0590053 ]]\n",
      "\n",
      "X_test_std_scaled:  [[-0.91107923  0.91107923 -1.01496917 ...  0.64065376  0.9793559\n",
      "   0.40123544]\n",
      " [-0.91107923  0.91107923  0.9852516  ...  0.64065376  0.9793559\n",
      "  -0.64634549]\n",
      " [ 1.09759938 -1.09759938  0.9852516  ... -1.56090554  0.9793559\n",
      "   1.23986288]\n",
      " ...\n",
      " [-0.91107923  0.91107923  0.9852516  ...  0.64065376  0.9793559\n",
      "  -0.00647153]\n",
      " [-0.91107923  0.91107923 -1.01496917 ...  0.64065376 -1.02107926\n",
      "  -0.88430587]\n",
      " [ 1.09759938 -1.09759938 -1.01496917 ...  0.64065376 -1.02107926\n",
      "  -0.95290003]]\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X_train_std_scaled = std_scaler.fit_transform(X_train)\n",
    "X_test_std_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "print(\"first line: \", X_train_std_scaled[0])\n",
    "print(\"X_train_std_scaled: \", X_train_std_scaled)\n",
    "print(\"\")\n",
    "print(\"X_test_std_scaled: \", X_test_std_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13e79a2f-89af-47c8-91b8-402fc1621a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_minmax_scaled:  [[1.         0.         0.         ... 0.         1.         0.70347065]\n",
      " [0.         1.         1.         ... 1.         1.         0.70746937]\n",
      " [0.         1.         0.         ... 1.         0.         0.11220426]\n",
      " ...\n",
      " [0.         1.         0.         ... 1.         1.         0.69033902]\n",
      " [0.         1.         1.         ... 1.         1.         0.70920092]\n",
      " [1.         0.         0.         ... 1.         1.         0.4833321 ]]\n",
      "\n",
      "X_test_minmax_scaled:  [[0.         1.         0.         ... 1.         1.         0.61627849]\n",
      " [0.         1.         1.         ... 1.         1.         0.3136714 ]\n",
      " [1.         0.         1.         ... 0.         1.         0.85852671]\n",
      " ...\n",
      " [0.         1.         1.         ... 1.         1.         0.49850715]\n",
      " [0.         1.         0.         ... 1.         0.         0.24493352]\n",
      " [1.         0.         0.         ... 1.         0.         0.22511922]]\n"
     ]
    }
   ],
   "source": [
    "minmax_scaler = MinMaxScaler()\n",
    "X_train_minmax_scaled = minmax_scaler.fit_transform(X_train)\n",
    "X_test_minmax_scaled = minmax_scaler.transform(X_test)\n",
    "\n",
    "print(\"X_train_minmax_scaled: \", X_train_minmax_scaled)\n",
    "print(\"\")\n",
    "print(\"X_test_minmax_scaled: \", X_test_minmax_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea13f843-3c84-4c30-a596-c534adc8fbdb",
   "metadata": {},
   "source": [
    "# 2. building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bad27116-7f0c-4c7a-b92b-8e839c9013ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std_scaled = torch.from_numpy(X_train_std_scaled).float()\n",
    "X_test_std_scaled = torch.from_numpy(X_test_std_scaled).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "X_train_minmax_scaled = torch.from_numpy(X_train_minmax_scaled).float()\n",
    "X_test_minmax_scaled = torch.from_numpy(X_test_minmax_scaled).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0e76a87-b076-4ae8-81d0-fbb0f4b4a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb98376d-9a8f-449c-85a0-e04ceff04fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "scaler = \"std\"\n",
    "if scaler == \"std\":\n",
    "    scaled_set = X_train_std_scaled\n",
    "elif scaler == \"minmax\":\n",
    "    scaled_set == X_train_minmax_scaled\n",
    "\n",
    "number_of_neurons = 8\n",
    "learning_batch_size = 32\n",
    "n_epochs = 200\n",
    "alpha = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b8f44c8-b6fc-474e-b00c-b24e06a9f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, input_size, seed=101):\n",
    "        super().__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fcl1 = nn.Linear(input_size, number_of_neurons)\n",
    "        self.fcl2 = nn.Linear(number_of_neurons, number_of_neurons)\n",
    "        self.fcl3 = nn.Linear(number_of_neurons, 1)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        signal = self.fcl1(data)\n",
    "        signal = F.relu(signal)\n",
    "        signal = self.fcl2(signal)\n",
    "        signal = F.relu(signal)\n",
    "        signal = self.fcl3(signal)\n",
    "        return F.sigmoid(signal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c8f4942-4937-4f8d-b585-26e25e408991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a torch Dataloader -> A DataLoader takes a dataset and provides an iterator over batches of data.\n",
    "# It handles batching, shuffling, and other data-loading functionalities, making it easier to work with large datasets.\n",
    "# the primary input dataset of the Dataloader is torch.utils.data.TensorDataset, BUT\n",
    "# any iterable can be used (e.g: torch.tensor, tuple), but X and y (independent and dependent variables) must be separeted\n",
    "# e.g: Dataloader(list(zip(X_train, y_train)))\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "dataloader = DataLoader(list(zip(scaled_set, y_train)), batch_size=learning_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7e51cf9-92b0-4666-b935-e6af9300c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rather \"bridge\" than \"brain\"\n",
    "brain = Network(scaled_set.shape[1])\n",
    "optimizer = Adam(brain.parameters(), lr=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517639cc-5e04-422d-aae9-8021d1ab7ea1",
   "metadata": {},
   "source": [
    "# 3. train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91338d38-d312-463a-ac48-0ced3ee98b36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 10 \t Loss: 0.2133\n",
      " Epoch: 20 \t Loss: 0.1224\n",
      " Epoch: 30 \t Loss: 0.1163\n",
      " Epoch: 40 \t Loss: 0.1132\n",
      " Epoch: 50 \t Loss: 0.1160\n",
      " Epoch: 60 \t Loss: 0.1138\n",
      " Epoch: 70 \t Loss: 0.1163\n",
      " Epoch: 80 \t Loss: 0.1183\n",
      " Epoch: 90 \t Loss: 0.1210\n",
      " Epoch: 100 \t Loss: 0.1231\n",
      " Epoch: 110 \t Loss: 0.1247\n",
      " Epoch: 120 \t Loss: 0.1274\n",
      " Epoch: 130 \t Loss: 0.1267\n",
      " Epoch: 140 \t Loss: 0.1250\n",
      " Epoch: 150 \t Loss: 0.1269\n",
      " Epoch: 160 \t Loss: 0.1287\n",
      " Epoch: 170 \t Loss: 0.1287\n",
      " Epoch: 180 \t Loss: 0.1295\n",
      " Epoch: 190 \t Loss: 0.1284\n",
      " Epoch: 200 \t Loss: 0.1294\n",
      "saved as:  bank_business_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    for features, labels in dataloader:\n",
    "        prediction = brain(features)\n",
    "        #print(\"feature: \", features)\n",
    "        #print(\"label: \", labels)\n",
    "        #print(\"prediction: \", prediction)\n",
    "        loss = F.binary_cross_entropy(prediction, labels)\n",
    "\n",
    "        #backpropagate\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # visualization:\n",
    "    # keep every X episode on the screen.\n",
    "    if epoch % 10 == 0: # if the remnant is 0, that means we are in a X step.\n",
    "        print(\"\\r Epoch: {} \\t Loss: {:.4f}\".format(epoch, loss.data))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "2 way to save:\n",
    "    1. save with state_dict() -> only the weights and biases of the layers. -> smaller, flexible (build different architecture on it) -> common way.\n",
    "    2. save the entire model -> complete, all the aspects incl. architechture -> \n",
    "\"\"\"\n",
    "save_name = \"bank_business_checkpoint.pth\"\n",
    "torch.save(brain.state_dict(), save_name)\n",
    "print(\"saved as: \", save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab7828-9926-456d-b24b-9e7848a2bea9",
   "metadata": {},
   "source": [
    "# 4. check model accuracy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e3ecd60-b5a6-4123-8b16-809111082810",
   "metadata": {},
   "source": [
    "# tests\n",
    "a = torch.tensor([0,1,0,1,0,1])\n",
    "b = torch.tensor([0,1,0,1,1,0])\n",
    "c = (a == b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "804b3931-0d30-4892-aa10-db75fd00e922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compared shape:  torch.Size([3000, 1]) \n",
      "\n",
      "compared:  tensor([[ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        ...,\n",
      "        [ True],\n",
      "        [False],\n",
      "        [False]]) \n",
      "\n",
      "\n",
      "accuracy: 0.8663\n",
      "confusin matrix: \n",
      " [[2260  118]\n",
      " [ 283  339]]\n"
     ]
    }
   ],
   "source": [
    "if scaler == \"std\":\n",
    "    test_X = X_test_std_scaled\n",
    "elif scaler == \"minmax\":\n",
    "    test_X = X_test_minmax_scaled\n",
    "\n",
    "brain.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = brain(test_X)\n",
    "\n",
    "# convert probabilities to 0 or 1\n",
    "threshold = 0.5\n",
    "y_pred_int = (y_pred >= threshold)\n",
    "\n",
    "# boolean masking\n",
    "compared = (y_pred_int == y_test)\n",
    "print(\"compared shape: \", compared.shape, \"\\n\")\n",
    "print(\"compared: \", compared, \"\\n\\n\")\n",
    "\n",
    "# accuracy\n",
    "accuracy = torch.sum(compared) / len(y_test)\n",
    "print(f\"accuracy: {accuracy :.4f}\")\n",
    "\n",
    "# confusion matrix\n",
    "matrix_acc = confusion_matrix(y_test, y_pred_int)\n",
    "print(\"confusin matrix: \\n\", matrix_acc)\n",
    "\n",
    "# save model test infos\n",
    "models.append({\n",
    "    \"last_loss\" : loss.data,\n",
    "    \"accuracy\" : accuracy,\n",
    "    \"scaler\" : scaler,\n",
    "    \"number_of_neurons\" : number_of_neurons,\n",
    "    \"learning_batch_size\" : learning_batch_size,\n",
    "    \"n_epochs\" : n_epochs,\n",
    "    \"alpha\" : alpha\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52d32081-0efd-4fc6-928c-b82c7ef01026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last_loss': tensor(0.1294), 'accuracy': tensor(0.8663), 'scaler': 'std', 'number_of_neurons': 8, 'learning_batch_size': 32, 'n_epochs': 200, 'alpha': 0.001}\n",
      "{'last_loss': tensor(0.1294), 'accuracy': tensor(0.8663), 'scaler': 'std', 'number_of_neurons': 8, 'learning_batch_size': 32, 'n_epochs': 200, 'alpha': 0.001}\n",
      "{'last_loss': tensor(0.1294), 'accuracy': tensor(0.8663), 'scaler': 'std', 'number_of_neurons': 8, 'learning_batch_size': 32, 'n_epochs': 200, 'alpha': 0.001}\n",
      "{'last_loss': tensor(0.1294), 'accuracy': tensor(0.8663), 'scaler': 'std', 'number_of_neurons': 8, 'learning_batch_size': 32, 'n_epochs': 200, 'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "for elem in models:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c4f9cad-b391-4c2b-9457-880afec5d8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  [[1.942867]]%\n"
     ]
    }
   ],
   "source": [
    "# predict from random data\n",
    "random_data = [0, 1, 1, 0, 0, 600, 40, 3, 60000, 2, 1, 1, 50000]\n",
    "brain.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = brain(torch.tensor(std_scaler.transform([random_data])).float())\n",
    "print(\"prediction: \", str(prediction.data.numpy() * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8465643-bc02-4b46-8d99-d2c36fe95266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
